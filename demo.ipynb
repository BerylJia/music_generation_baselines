{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dataset ``lpd_5_cleansed`` from [Lakh Pianoroll Dataset](https://salu133445.github.io/lakh-pianoroll-dataset/dataset).\n",
    "\n",
    "I cut each song into 400 time steps, removed the lowest 20 pitches and the highest 24 pitches, and made a .npy file called ``lpd_5_cleansed.npy``. Shape is: 21425(song) &times; 400(time step) &times; 84(note) &times; 5(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21425, 400, 84, 5)\n",
      "(21425, 400, 420)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_file = './data/lpd_5_cleansed.npy'\n",
    "data = np.load(data_file)\n",
    "print(np.shape(data))\n",
    "\n",
    "data = np.reshape(data, [21425, 400, -1])\n",
    "print(np.shape(data))\n",
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "from utils.dataset_helper import read_data_sets\n",
    "\n",
    "dataset = read_data_sets(data)\n",
    "train_set = dataset.train\n",
    "develop_set = dataset.develop\n",
    "test_set = dataset.test\n",
    "\n",
    "# release space\n",
    "del data\n",
    "del dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.rnn import RNN\n",
    "\n",
    "model = RNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying to restore saved checkpoints from ./logdir/20180518-1030/train ... No checkpoint found.\n",
      "\n",
      "Epoch 1 [batch 100] > train loss: 0.0405 develop loss: 0.0438 \n",
      "Epoch 1 [batch 200] > train loss: 0.0544 develop loss: 0.0571 \n",
      "Epoch 1 [batch 300] > train loss: 0.0472 develop loss: 0.0535 \n",
      "Epoch 1 [batch 400] > train loss: 0.0443 develop loss: 0.0511 \n",
      "Epoch 1 [batch 500] > train loss: 0.0562 develop loss: 0.0533 \n",
      "Epoch 1 [batch 600] > train loss: 0.0394 develop loss: 0.0473 \n",
      "Epoch 1 [batch 700] > train loss: 0.0493 develop loss: 0.0424 \n",
      "Epoch 1 [batch 800] > train loss: 0.0517 develop loss: 0.0517 \n",
      "Epoch 1 [batch 900] > train loss: 0.0489 develop loss: 0.0513 \n",
      "Epoch 1 [batch 1000] > train loss: 0.0547 develop loss: 0.0503 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 2 [batch 100] > train loss: 0.0449 develop loss: 0.0418 \n",
      "Epoch 2 [batch 200] > train loss: 0.0323 develop loss: 0.0469 \n",
      "Epoch 2 [batch 300] > train loss: 0.0395 develop loss: 0.0420 \n",
      "Epoch 2 [batch 400] > train loss: 0.0399 develop loss: 0.0478 \n",
      "Epoch 2 [batch 500] > train loss: 0.0287 develop loss: 0.0384 \n",
      "Epoch 2 [batch 600] > train loss: 0.0330 develop loss: 0.0375 \n",
      "Epoch 2 [batch 700] > train loss: 0.0351 develop loss: 0.0293 \n",
      "Epoch 2 [batch 800] > train loss: 0.0272 develop loss: 0.0331 \n",
      "Epoch 2 [batch 900] > train loss: 0.0274 develop loss: 0.0312 \n",
      "Epoch 2 [batch 1000] > train loss: 0.0344 develop loss: 0.0265 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 3 [batch 100] > train loss: 0.0346 develop loss: 0.0308 \n",
      "Epoch 3 [batch 200] > train loss: 0.0238 develop loss: 0.0343 \n",
      "Epoch 3 [batch 300] > train loss: 0.0212 develop loss: 0.0280 \n",
      "Epoch 3 [batch 400] > train loss: 0.0273 develop loss: 0.0276 \n",
      "Epoch 3 [batch 500] > train loss: 0.0294 develop loss: 0.0204 \n",
      "Epoch 3 [batch 600] > train loss: 0.0221 develop loss: 0.0280 \n",
      "Epoch 3 [batch 700] > train loss: 0.0258 develop loss: 0.0239 \n",
      "Epoch 3 [batch 800] > train loss: 0.0243 develop loss: 0.0259 \n",
      "Epoch 3 [batch 900] > train loss: 0.0231 develop loss: 0.0229 \n",
      "Epoch 3 [batch 1000] > train loss: 0.0161 develop loss: 0.0181 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 4 [batch 100] > train loss: 0.0203 develop loss: 0.0193 \n",
      "Epoch 4 [batch 200] > train loss: 0.0222 develop loss: 0.0156 \n",
      "Epoch 4 [batch 300] > train loss: 0.0235 develop loss: 0.0193 \n",
      "Epoch 4 [batch 400] > train loss: 0.0130 develop loss: 0.0139 \n",
      "Epoch 4 [batch 500] > train loss: 0.0172 develop loss: 0.0152 \n",
      "Epoch 4 [batch 600] > train loss: 0.0167 develop loss: 0.0233 \n",
      "Epoch 4 [batch 700] > train loss: 0.0186 develop loss: 0.0187 \n",
      "Epoch 4 [batch 800] > train loss: 0.0145 develop loss: 0.0183 \n",
      "Epoch 4 [batch 900] > train loss: 0.0156 develop loss: 0.0115 \n",
      "Epoch 4 [batch 1000] > train loss: 0.0112 develop loss: 0.0178 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 5 [batch 100] > train loss: 0.0094 develop loss: 0.0139 \n",
      "Epoch 5 [batch 200] > train loss: 0.0146 develop loss: 0.0135 \n",
      "Epoch 5 [batch 300] > train loss: 0.0122 develop loss: 0.0098 \n",
      "Epoch 5 [batch 400] > train loss: 0.0112 develop loss: 0.0089 \n",
      "Epoch 5 [batch 500] > train loss: 0.0123 develop loss: 0.0125 \n",
      "Epoch 5 [batch 600] > train loss: 0.0125 develop loss: 0.0107 \n",
      "Epoch 5 [batch 700] > train loss: 0.0116 develop loss: 0.0108 \n",
      "Epoch 5 [batch 800] > train loss: 0.0098 develop loss: 0.0111 \n",
      "Epoch 5 [batch 900] > train loss: 0.0100 develop loss: 0.0094 \n",
      "Epoch 5 [batch 1000] > train loss: 0.0090 develop loss: 0.0109 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 6 [batch 100] > train loss: 0.0107 develop loss: 0.0082 \n",
      "Epoch 6 [batch 200] > train loss: 0.0058 develop loss: 0.0105 \n",
      "Epoch 6 [batch 300] > train loss: 0.0083 develop loss: 0.0091 \n",
      "Epoch 6 [batch 400] > train loss: 0.0049 develop loss: 0.0064 \n",
      "Epoch 6 [batch 500] > train loss: 0.0114 develop loss: 0.0118 \n",
      "Epoch 6 [batch 600] > train loss: 0.0054 develop loss: 0.0069 \n",
      "Epoch 6 [batch 700] > train loss: 0.0066 develop loss: 0.0086 \n",
      "Epoch 6 [batch 800] > train loss: 0.0069 develop loss: 0.0083 \n",
      "Epoch 6 [batch 900] > train loss: 0.0087 develop loss: 0.0085 \n",
      "Epoch 6 [batch 1000] > train loss: 0.0037 develop loss: 0.0076 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 7 [batch 100] > train loss: 0.0065 develop loss: 0.0080 \n",
      "Epoch 7 [batch 200] > train loss: 0.0067 develop loss: 0.0081 \n",
      "Epoch 7 [batch 300] > train loss: 0.0051 develop loss: 0.0067 \n",
      "Epoch 7 [batch 400] > train loss: 0.0085 develop loss: 0.0071 \n",
      "Epoch 7 [batch 500] > train loss: 0.0073 develop loss: 0.0077 \n",
      "Epoch 7 [batch 600] > train loss: 0.0080 develop loss: 0.0062 \n",
      "Epoch 7 [batch 700] > train loss: 0.0067 develop loss: 0.0062 \n",
      "Epoch 7 [batch 800] > train loss: 0.0052 develop loss: 0.0080 \n",
      "Epoch 7 [batch 900] > train loss: 0.0055 develop loss: 0.0071 \n",
      "Epoch 7 [batch 1000] > train loss: 0.0061 develop loss: 0.0049 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 8 [batch 100] > train loss: 0.0061 develop loss: 0.0059 \n",
      "Epoch 8 [batch 200] > train loss: 0.0048 develop loss: 0.0059 \n",
      "Epoch 8 [batch 300] > train loss: 0.0052 develop loss: 0.0060 \n",
      "Epoch 8 [batch 400] > train loss: 0.0058 develop loss: 0.0075 \n",
      "Epoch 8 [batch 500] > train loss: 0.0040 develop loss: 0.0032 \n",
      "Epoch 8 [batch 600] > train loss: 0.0045 develop loss: 0.0045 \n",
      "Epoch 8 [batch 700] > train loss: 0.0043 develop loss: 0.0049 \n",
      "Epoch 8 [batch 800] > train loss: 0.0044 develop loss: 0.0048 \n",
      "Epoch 8 [batch 900] > train loss: 0.0043 develop loss: 0.0030 \n",
      "Epoch 8 [batch 1000] > train loss: 0.0038 develop loss: 0.0033 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 9 [batch 100] > train loss: 0.0075 develop loss: 0.0046 \n",
      "Epoch 9 [batch 200] > train loss: 0.0034 develop loss: 0.0045 \n",
      "Epoch 9 [batch 300] > train loss: 0.0050 develop loss: 0.0042 \n",
      "Epoch 9 [batch 400] > train loss: 0.0046 develop loss: 0.0049 \n",
      "Epoch 9 [batch 500] > train loss: 0.0038 develop loss: 0.0043 \n",
      "Epoch 9 [batch 600] > train loss: 0.0036 develop loss: 0.0039 \n",
      "Epoch 9 [batch 700] > train loss: 0.0041 develop loss: 0.0065 \n",
      "Epoch 9 [batch 800] > train loss: 0.0045 develop loss: 0.0051 \n",
      "Epoch 9 [batch 900] > train loss: 0.0039 develop loss: 0.0064 \n",
      "Epoch 9 [batch 1000] > train loss: 0.0044 develop loss: 0.0028 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 10 [batch 100] > train loss: 0.0037 develop loss: 0.0045 \n",
      "Epoch 10 [batch 200] > train loss: 0.0044 develop loss: 0.0044 \n",
      "Epoch 10 [batch 300] > train loss: 0.0025 develop loss: 0.0045 \n",
      "Epoch 10 [batch 400] > train loss: 0.0034 develop loss: 0.0027 \n",
      "Epoch 10 [batch 500] > train loss: 0.0044 develop loss: 0.0034 \n",
      "Epoch 10 [batch 600] > train loss: 0.0032 develop loss: 0.0034 \n",
      "Epoch 10 [batch 700] > train loss: 0.0031 develop loss: 0.0040 \n",
      "Epoch 10 [batch 800] > train loss: 0.0033 develop loss: 0.0034 \n",
      "Epoch 10 [batch 900] > train loss: 0.0023 develop loss: 0.0056 \n",
      "Epoch 10 [batch 1000] > train loss: 0.0026 develop loss: 0.0032 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 11 [batch 100] > train loss: 0.0032 develop loss: 0.0037 \n",
      "Epoch 11 [batch 200] > train loss: 0.0034 develop loss: 0.0030 \n",
      "Epoch 11 [batch 300] > train loss: 0.0028 develop loss: 0.0043 \n",
      "Epoch 11 [batch 400] > train loss: 0.0024 develop loss: 0.0024 \n",
      "Epoch 11 [batch 500] > train loss: 0.0029 develop loss: 0.0023 \n",
      "Epoch 11 [batch 600] > train loss: 0.0026 develop loss: 0.0018 \n",
      "Epoch 11 [batch 700] > train loss: 0.0023 develop loss: 0.0032 \n",
      "Epoch 11 [batch 800] > train loss: 0.0021 develop loss: 0.0030 \n",
      "Epoch 11 [batch 900] > train loss: 0.0036 develop loss: 0.0021 \n",
      "Epoch 11 [batch 1000] > train loss: 0.0021 develop loss: 0.0020 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 12 [batch 100] > train loss: 0.0031 develop loss: 0.0025 \n",
      "Epoch 12 [batch 200] > train loss: 0.0012 develop loss: 0.0025 \n",
      "Epoch 12 [batch 300] > train loss: 0.0021 develop loss: 0.0019 \n",
      "Epoch 12 [batch 400] > train loss: 0.0019 develop loss: 0.0017 \n",
      "Epoch 12 [batch 500] > train loss: 0.0031 develop loss: 0.0032 \n",
      "Epoch 12 [batch 600] > train loss: 0.0027 develop loss: 0.0034 \n",
      "Epoch 12 [batch 700] > train loss: 0.0015 develop loss: 0.0025 \n",
      "Epoch 12 [batch 800] > train loss: 0.0027 develop loss: 0.0031 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 [batch 900] > train loss: 0.0015 develop loss: 0.0029 \n",
      "Epoch 12 [batch 1000] > train loss: 0.0017 develop loss: 0.0020 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 13 [batch 100] > train loss: 0.0018 develop loss: 0.0028 \n",
      "Epoch 13 [batch 200] > train loss: 0.0017 develop loss: 0.0037 \n",
      "Epoch 13 [batch 300] > train loss: 0.0017 develop loss: 0.0019 \n",
      "Epoch 13 [batch 400] > train loss: 0.0021 develop loss: 0.0017 \n",
      "Epoch 13 [batch 500] > train loss: 0.0026 develop loss: 0.0020 \n",
      "Epoch 13 [batch 600] > train loss: 0.0022 develop loss: 0.0025 \n",
      "Epoch 13 [batch 700] > train loss: 0.0016 develop loss: 0.0015 \n",
      "Epoch 13 [batch 800] > train loss: 0.0020 develop loss: 0.0026 \n",
      "Epoch 13 [batch 900] > train loss: 0.0010 develop loss: 0.0012 \n",
      "Epoch 13 [batch 1000] > train loss: 0.0017 develop loss: 0.0026 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 14 [batch 100] > train loss: 0.0018 develop loss: 0.0014 \n",
      "Epoch 14 [batch 200] > train loss: 0.0017 develop loss: 0.0019 \n",
      "Epoch 14 [batch 300] > train loss: 0.0017 develop loss: 0.0017 \n",
      "Epoch 14 [batch 400] > train loss: 0.0022 develop loss: 0.0022 \n",
      "Epoch 14 [batch 500] > train loss: 0.0013 develop loss: 0.0016 \n",
      "Epoch 14 [batch 600] > train loss: 0.0014 develop loss: 0.0026 \n",
      "Epoch 14 [batch 700] > train loss: 0.0016 develop loss: 0.0012 \n",
      "Epoch 14 [batch 800] > train loss: 0.0018 develop loss: 0.0031 \n",
      "Epoch 14 [batch 900] > train loss: 0.0015 develop loss: 0.0011 \n",
      "Epoch 14 [batch 1000] > train loss: 0.0022 develop loss: 0.0020 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 15 [batch 100] > train loss: 0.0018 develop loss: 0.0017 \n",
      "Epoch 15 [batch 200] > train loss: 0.0019 develop loss: 0.0019 \n",
      "Epoch 15 [batch 300] > train loss: 0.0018 develop loss: 0.0016 \n",
      "Epoch 15 [batch 400] > train loss: 0.0018 develop loss: 0.0022 \n",
      "Epoch 15 [batch 500] > train loss: 0.0025 develop loss: 0.0014 \n",
      "Epoch 15 [batch 600] > train loss: 0.0013 develop loss: 0.0015 \n",
      "Epoch 15 [batch 700] > train loss: 0.0011 develop loss: 0.0023 \n",
      "Epoch 15 [batch 800] > train loss: 0.0021 develop loss: 0.0021 \n",
      "Epoch 15 [batch 900] > train loss: 0.0012 develop loss: 0.0025 \n",
      "Epoch 15 [batch 1000] > train loss: 0.0016 develop loss: 0.0022 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 16 [batch 100] > train loss: 0.0010 develop loss: 0.0019 \n",
      "Epoch 16 [batch 200] > train loss: 0.0012 develop loss: 0.0012 \n",
      "Epoch 16 [batch 300] > train loss: 0.0010 develop loss: 0.0016 \n",
      "Epoch 16 [batch 400] > train loss: 0.0016 develop loss: 0.0010 \n",
      "Epoch 16 [batch 500] > train loss: 0.0016 develop loss: 0.0023 \n",
      "Epoch 16 [batch 600] > train loss: 0.0009 develop loss: 0.0012 \n",
      "Epoch 16 [batch 700] > train loss: 0.0022 develop loss: 0.0019 \n",
      "Epoch 16 [batch 800] > train loss: 0.0008 develop loss: 0.0014 \n",
      "Epoch 16 [batch 900] > train loss: 0.0016 develop loss: 0.0019 \n",
      "Epoch 16 [batch 1000] > train loss: 0.0013 develop loss: 0.0012 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 17 [batch 100] > train loss: 0.0012 develop loss: 0.0018 \n",
      "Epoch 17 [batch 200] > train loss: 0.0011 develop loss: 0.0010 \n",
      "Epoch 17 [batch 300] > train loss: 0.0013 develop loss: 0.0013 \n",
      "Epoch 17 [batch 400] > train loss: 0.0008 develop loss: 0.0013 \n",
      "Epoch 17 [batch 500] > train loss: 0.0016 develop loss: 0.0013 \n",
      "Epoch 17 [batch 600] > train loss: 0.0009 develop loss: 0.0011 \n",
      "Epoch 17 [batch 700] > train loss: 0.0008 develop loss: 0.0009 \n",
      "Epoch 17 [batch 800] > train loss: 0.0010 develop loss: 0.0010 \n",
      "Epoch 17 [batch 900] > train loss: 0.0008 develop loss: 0.0008 \n",
      "Epoch 17 [batch 1000] > train loss: 0.0009 develop loss: 0.0018 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 18 [batch 100] > train loss: 0.0008 develop loss: 0.0015 \n",
      "Epoch 18 [batch 200] > train loss: 0.0012 develop loss: 0.0017 \n",
      "Epoch 18 [batch 300] > train loss: 0.0012 develop loss: 0.0013 \n",
      "Epoch 18 [batch 400] > train loss: 0.0009 develop loss: 0.0011 \n",
      "Epoch 18 [batch 500] > train loss: 0.0009 develop loss: 0.0006 \n",
      "Epoch 18 [batch 600] > train loss: 0.0011 develop loss: 0.0025 \n",
      "Epoch 18 [batch 700] > train loss: 0.0015 develop loss: 0.0014 \n",
      "Epoch 18 [batch 800] > train loss: 0.0009 develop loss: 0.0008 \n",
      "Epoch 18 [batch 900] > train loss: 0.0007 develop loss: 0.0006 \n",
      "Epoch 18 [batch 1000] > train loss: 0.0011 develop loss: 0.0007 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 19 [batch 100] > train loss: 0.0008 develop loss: 0.0015 \n",
      "Epoch 19 [batch 200] > train loss: 0.0006 develop loss: 0.0016 \n",
      "Epoch 19 [batch 300] > train loss: 0.0014 develop loss: 0.0006 \n",
      "Epoch 19 [batch 400] > train loss: 0.0008 develop loss: 0.0025 \n",
      "Epoch 19 [batch 500] > train loss: 0.0016 develop loss: 0.0012 \n",
      "Epoch 19 [batch 600] > train loss: 0.0006 develop loss: 0.0019 \n",
      "Epoch 19 [batch 700] > train loss: 0.0008 develop loss: 0.0012 \n",
      "Epoch 19 [batch 800] > train loss: 0.0012 develop loss: 0.0015 \n",
      "Epoch 19 [batch 900] > train loss: 0.0007 develop loss: 0.0010 \n",
      "Epoch 19 [batch 1000] > train loss: 0.0007 develop loss: 0.0011 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Epoch 20 [batch 100] > train loss: 0.0006 develop loss: 0.0011 \n",
      "Epoch 20 [batch 200] > train loss: 0.0009 develop loss: 0.0015 \n",
      "Epoch 20 [batch 300] > train loss: 0.0007 develop loss: 0.0008 \n",
      "Epoch 20 [batch 400] > train loss: 0.0010 develop loss: 0.0015 \n",
      "Epoch 20 [batch 500] > train loss: 0.0005 develop loss: 0.0008 \n",
      "Epoch 20 [batch 600] > train loss: 0.0012 develop loss: 0.0006 \n",
      "Epoch 20 [batch 700] > train loss: 0.0008 develop loss: 0.0004 \n",
      "Epoch 20 [batch 800] > train loss: 0.0005 develop loss: 0.0007 \n",
      "Epoch 20 [batch 900] > train loss: 0.0007 develop loss: 0.0008 \n",
      "Epoch 20 [batch 1000] > train loss: 0.0006 develop loss: 0.0010 \n",
      "Storing checkpoint to ./logdir/20180518-1030/train ... Done.\n",
      "Training done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_tag = \"20180518-1030\"\n",
    "model.train(train_set, develop_set, log_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./logdir/20180518-1030/results/Train.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "from utils.ops import plot_gif\n",
    "\n",
    "plot_gif(fig_dir='./logdir/%s/results' % log_tag)\n",
    "Image(url='./logdir/%s/results/Train.gif' % log_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0009 \n",
      "Write to midi file './logdir/20180518-1030/results/Test.mid' done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"./logdir/20180518-1030/results/Test.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(test_set, log_tag)\n",
    "Image(url='./logdir/%s/results/Test.png' % log_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
